{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ttODwCFd8K0Q"},"source":["# Access the MentalRiskEs data and interact with the server\n","\n","This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes/) evaluation campaign at IberLEF 2023.\n","\n","**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n","\n","**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n","\n","Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2DJN0pXx8W3-"},"source":["# Install CodeCarbon package"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17890,"status":"ok","timestamp":1684832097060,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"-G15M4JxWHR9","outputId":"51128c63-30fe-49ce-8ec8-42f9b66af446"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5963,"status":"ok","timestamp":1684832103020,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"wdvPWyc6x9cV","outputId":"602abe87-adbc-414b-fa3b-2addf5223ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting codecarbon\n","  Downloading codecarbon-2.2.1-py3-none-any.whl (171 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.3/171.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting arrow (from codecarbon)\n","  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.5.3)\n","Collecting pynvml (from codecarbon)\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.27.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\n","Collecting fuzzywuzzy (from codecarbon)\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.3)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.22.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n","Installing collected packages: fuzzywuzzy, pynvml, arrow, codecarbon\n","Successfully installed arrow-1.2.3 codecarbon-2.2.1 fuzzywuzzy-0.18.0 pynvml-11.5.0\n"]}],"source":["!pip install codecarbon"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25028,"status":"ok","timestamp":1684832128043,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"3JMg1EFofgbj","outputId":"d0613f41-49e7-4d47-b0e0-7aebb725041b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.28.0\n","  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence-transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19 (from datasets)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Collecting sentencepiece (from sentence-transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=bdacd0008ee95964685dcac9437408085abb949bdabb0f91b4083c6e601756b8\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, sentence-transformers, accelerate\n","Successfully installed accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.28.0 xxhash-3.2.0 yarl-1.9.2\n"]}],"source":["!pip install transformers==4.28.0 accelerate datasets sentence-transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dqyN-7TcXbL8"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sqih7m6tN4MT"},"outputs":[],"source":["import requests, zipfile, io\n","from typing import List, Dict\n","from requests.adapters import HTTPAdapter, Retry\n","import random\n","import json\n","import os\n","import pandas as pd\n","from codecarbon import EmissionsTracker"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1684832128923,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"SQlYmgdHWQ4h","outputId":"d1a978b3-6aaa-4d1b-fd60-a4d7280df24e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Master/NLP/MentalRISK2023-Task2/Código\n"]}],"source":["%cd /content/drive/MyDrive/Master/NLP/MentalRISK2023-Task2/Código"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CHGGrr3GXdIb"},"source":["# Endpoints\n","These URL addresses are necessary for the connection to the server. \n","\n","**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdQPl8lbOKsg"},"outputs":[],"source":["URL = \"http://s3-ceatic.ujaen.es:8036/\"  \n","TOKEN = \"c90775da4a16e3d5ed1cda75fa9d53424dc7ba78\" \n","\n","# Download endpoints\n","ENDPOINT_DOWNLOAD_MESSAGES_TRIAL = URL+\"{TASK}/download_trial/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_GOLD_TRIAL = URL+\"{SUBTASK}/download_trial/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_MESSAGES_TRAIN = URL+\"{TASK}/download_train/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_GOLD_TRAIN = URL+\"{SUBTASK}/download_train/{TOKEN}\"\n","\n","# Trial endpoints\n","ENDPOINT_GET_MESSAGES_TRIAL = URL+\"{TASK}/getmessages_trial/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"{SUBTASK}/submit_trial/{TOKEN}/{RUN}\"\n","\n","# Test endpoints\n","ENDPOINT_GET_MESSAGES = URL+\"{TASK}/getmessages/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS = URL+\"{SUBTASK}/submit/{TOKEN}/{RUN}\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WgHNiyxHR5AJ"},"source":["# Download Data\n","To download the data, you can make use of the **functions defined in the following**.\n","\n","The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes/evaluation)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uaeh23C5R1lG"},"outputs":[],"source":["def download_messages_trial(task: str,subtasks:List[str], token: str) -> List[Dict]:\n","    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRIAL.format(TASK=task, TOKEN=token))\n","\n","    if response.status_code != 200:\n","        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","    else:\n","      z = zipfile.ZipFile(io.BytesIO(response.content))\n","      os.makedirs(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n","      z.extractall(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n","\n","    for subtask in subtasks:\n","        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRIAL.format(SUBTASK=subtask, TOKEN=token))\n","        \n","        if response.status_code != 200:\n","            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","        else:\n","          file_object = open(\"./data/{task}/trial/gold_trial_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n","          file_object.write(response.text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VIqRCv3OS3Bn"},"source":["# Client Server\n","This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests. \n","\n","**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fppw71j0WeQB"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11285,"status":"ok","timestamp":1684832152949,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"ud8jzPvqWk3m","outputId":"6c672cd8-7b77-4af4-ade6-3965155dae59"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Master/NLP/MentalRISK2023-Task2/Código/modeloD\n","/content/drive/MyDrive/Master/NLP/MentalRISK2023-Task2/Código\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultiOutputRegressor from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}],"source":["%cd modeloD\n","import config as d_conf\n","import task_d\n","model_d_ = task_d.load_model(d_conf.MODEL_PATH, d_conf.SERIALIZATION_METHOD)\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSo-VKMSmTNa"},"outputs":[],"source":["class ModelD:\n","\n","  def __init__(self, model):\n","      self.model = model\n","\n","  def scale_predict(self, y):\n","    y = y/y.sum(axis=1).reshape(-1, 1)\n","    return y\n","  \n","  def predict(self, messages:list):\n","    # make predictions\n","    y_pred = self.scale_predict(self.model.predict(messages))\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JF31D7KpvXR4"},"outputs":[],"source":["messages = task_d.load_data('modeloD/server_test.json').to_dict(orient='records')[:20]\n","messages_df = task_d.preprocess_test_data(pd.DataFrame(messages))\n","messages = messages_df['message'].tolist()\n","tokenized_messages = [tokenize(m) for m in messages]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":718,"status":"ok","timestamp":1684832608011,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"QGyGWpBmvlCh","outputId":"67b7ffb7-f73b-47e9-df5a-032be607aaac"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"modeloB\")\n","model_b = Trainer(\n","  model=model,\n","  args=TrainingArguments(\"./loaded_outputs_b\"),\n","  eval_dataset=messages\n",")\n","b_pred = model_b.predict(tokenized_messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684832789322,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"egDGxVlY2j4i","outputId":"ce31cb29-0ca2-4b08-bad3-36b6e725a897"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","-0 Hoy es un dia hermoso , y somos personas hermosas , hagamos lo que nos gusta , no dejemos que un segundo feo nos arruine el dia , hay que vivir chicoos , siempre sonriendo\n","-1 Y pues la anclo para quien sepa responder | O una serie de preguntas mejor dicho\n","-2 Yo creo que si solo te lo puede sacar el porque tiene tu pasaporte , se lo digas , un dia se lo tendras que decir . Mas tardes mas se alarga tu espera x irte\n","-3 Forma parte de vivir todos o bueno almenos una parte desea morirse en la vida nosotros la vivimos mas dura pero es una razon por la cual seguir fuerte cada dia\n","-4 no estudie , lo hacia por gusto antes de meterme en la depresión\n","-5 Ni granadino ni malagueño\n","-6 Kawaii se fuerte , orgulleselo con triunfos , logros\n","-7 Buen día mi nombre es Guillermo , tengo 48 años el próximo 12 de diciembre cumpliré 49 años , hace 10 años decidí dejar de consumir sustancias ilícitas , antes sentía que no valía nada y mi vida era una porquería , lo había dejado todo porque quería vivir anestesiado , tratando de conseguir una felicidad efímera , momentánea que solo duraba un momento , me estaba matando poco a poco y creía que eso me hacía feliz , hoy día tengo problemas que se convierten en metas , no tengo casa propia , pero vivo con mi familia , algo disfuncionales pero aprendí a quererlos como son , mi anterior pareja , la cual quiero mucho viajo fuera del país y eso trajo más que nuestra separación física la separación espiritual , me duele mucho , pero tengo que aceptarlo , hoy día Dios puso en mi camino una hermosa mujer la cual tiene muchas cualidades y aptitudes que me hacen sentir bien y enamorarme de ella cada día , tengo un hijo de 19 años que hace 2 no veo eso me entristece , pero seguro volveremos a estar juntos , tengo dos trabajos , que mas que trabajo es mi propósito de vida donde apoyo a adolescentes y adultos a ver la vida desde otro punto de vista y dejar las adicciones , con todo esto tengo 2 opciones , morir cada día pensando que mi vida es una mierda o ver lo bueno que tengo y ser feliz cada día para disfrutar de cada amanecer e irme a dormir dando gracias por un día mas\n","-8 Ya que no se ve y no duele\n","-9 Tuve una sobredosis el año pasado por cuestiones de los pam\n","-10 Duele estar entubado por 1 mes y duele despues verte al espejo y ver todas las cicatrices que tienes y q pierdas la mitad de la vision y el sonido del oido derecho\n","-11 Yo quiero tener una mascota , sea un perro o un gato\n","-12 No entiendo q os pasa | Aaaa m estas haciendo daño ?\n","-13 El único modo es hacerte fuerte y forjar tu carácter\n","-14 Porque estas en depresión ?\n","-15 Yo ? No .. jaja .. tengo un rato ya por aca\n","-16 Yo no insulto . Ni odio ni invento . Ni ayudo a la gente con stickers de mierda\n","-17 Y0 me siento fea inutil y me lastime un par de veses ahora estaba curandome las heridas\n"]}],"source":["print(''.join(f'\\n-{i} {m}' for i,m in enumerate(messages)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfHe3T-hvno5"},"outputs":[],"source":["import torch\n","out = model(torch.tensor([a['input_ids'] for a in tokenized_messages]))"]},{"cell_type":"code","execution_count":141,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1684838388422,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"l0kONpltS2R9"},"outputs":[],"source":["from transformers import AutoTokenizer\n","from pprint import pprint\n","\n","model_name=\"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","MAX_LENGTH = 512\n","\n","def tokenize(example):\n","     return tokenizer(example, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n","     #return tokenizer(example[\"message\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n","    \n","class Client_task2:\n","    def __init__(self, task: str, subtasks: List[str], token: str, number_of_runs: int, tracker: EmissionsTracker):\n","        # Task in which you participate\n","        self.task = task\n","        # Subtasks in which you participate\n","        self.subtasks = subtasks\n","        # Token identifier\n","        self.token = token\n","        # Number of runs (Max: 3)\n","        self.number_of_runs = number_of_runs\n","        # Object to calculate CO2 emissions\n","        self.tracker = tracker\n","        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy', 'ram_energy', \n","            'energy_consumed', 'cpu_count', 'gpu_count', 'cpu_model', 'gpu_model', 'ram_total_size']\n","\n","    # Here a GET request is sent to the server to extract the data.\n","    def get_messages(self, retries: int, backoff: float) -> Dict:\n","        session = requests.Session()\n","        retries = Retry( \n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","        response = session.get(ENDPOINT_GET_MESSAGES.format(TASK=self.task, TOKEN=self.token))\n","        if response.status_code != 200:\n","          print(\"GET - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","          return []\n","        else:\n","          return json.loads(response.content)\n","\n","    # The POST requests are sent to the server to send predictions and carbon emission data\n","    def submit_decission(self, subtask: int, decisions: Dict, emissions:Dict, retries, backoff):\n","\n","        data = {\n","            \"predictions\": decisions,\n","            \"emissions\": emissions\n","        }\n","\n","        data = json.dumps(data)\n","        # Session to POST request\n","        session = requests.Session()\n","        retries = Retry(\n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","\n","        for run in range(0,self.number_of_runs):\n","            # For each run, new decisions\n","            response = session.post(ENDPOINT_SUBMIT_DECISIONS.format(SUBTASK=self.subtasks[subtask], TOKEN=self.token, RUN=run), json=[data])\n","            if response.status_code != 200:\n","                print(\"POST - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","            else:\n","                print(\"Subtask {}: - run {}\".format(self.subtasks[subtask], run))\n","        \n","\n","    # Main thread\n","    def run_task2(self, retries: int, backoff: float):\n","        # Get messages for taskX\n","        messages = self.get_messages(retries, backoff)\n","        # messages = task_d.load_data('modeloD/server_test.json').to_dict(orient='records')[:20]\n","        # If there are no messages\n","        if len(messages) == 0:\n","            print(\"All rounds processed\")\n","            return\n","\n","            \n","        # # carga de modelo\n","        # # A\n","        # model = AutoModelForSequenceClassification.from_pretrained(\"modeloA\")\n","        # model_a = Trainer(\n","        #   model=model,\n","        #   args=TrainingArguments(\"./loaded_outputs_a\"),\n","        #   eval_dataset=messages\n","        # )\n","\n","        #model_a.evaluate()\n","\n","        # B\n","        model = AutoModelForSequenceClassification.from_pretrained(\"modeloB\")\n","        model_b = Trainer(\n","          model=model,\n","          args=TrainingArguments(\"./loaded_outputs_b\"),\n","          eval_dataset=messages\n","        )\n","\n","        # C\n","        # model = AutoModelForSequenceClassification.from_pretrained(\"modeloC\")\n","        # model_c = Trainer(\n","        #   model=model,\n","        #   args=TrainingArguments(\"./loaded_outputs_c\"),\n","        #   eval_dataset=messages\n","        # )\n","\n","        #model_c.evaluate()\n","\n","        # D\n","        model_d = ModelD(model_d_)\n","        \n","        # c_labels = {'suffer+against': 0, 'suffer+in favour': 1, 'suffer+other': 2, 'control': 3}\n","        # c_labels_rev = {v:k for k,v in c_labels.items()}\n","\n","        while len(messages) > 0:\n","            # messages[0]['round'] = 1\n","            print(\"------------------- Processing round {}\".format(messages[0][\"round\"]))\n","            # Save subjects\n","            with open('./data/rounds_trial/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n","                json.dump(messages, json_file, ensure_ascii=False)\n","              \n","            pprint(messages)\n","\n","            # Calculate emissions for each prediction\n","            messages_df = task_d.preprocess_test_data(pd.DataFrame(messages))\n","            messages = messages_df['message'].tolist()\n","            tokenized_messages = [tokenize(m) for m in messages]\n","            print(\"First messages:\",messages[:2])\n","\n","            # task b\n","            self.tracker.start()\n","            print(\"predicting task B...\")\n","            b_pred_raw = model_b.predict(tokenized_messages)\n","            b_pred = np.clip(b_pred_raw.predictions, 0, 1)\n","            print(b_pred)\n","            b_pred_df = pd.DataFrame(b_pred, columns=['pred_b'])\n","            b_pred_df = pd.concat([messages_df[['nick']], b_pred_df], axis=1)\\\n","                .groupby('nick')\\\n","                .first()\n","            decisionsB = b_pred_df['pred_b'].apply(lambda x: np.round(x, 5)).to_dict()\n","            print(\"Decisions B:\")\n","            pprint(decisionsB)\n","        \n","            # task a\n","            decisionsA = b_pred_df['pred_b'].round().astype(int).to_dict()\n","            print(\"Decisions A:\")\n","            pprint(decisionsA)\n","            \n","            print(\"Emmisions of A and B:\")\n","            self.tracker.stop()\n","            df = pd.read_csv(\"emissions.csv\")\n","            measurementsAB = df.iloc[-1][self.relevant_cols].to_dict()\n","            pprint(measurementsAB)\n","\n","            print(\"predicting task D...\")\n","            self.tracker.start()\n","            d_pred = model_d.predict(messages)\n","            d_pred_df = pd.DataFrame(d_pred, columns=task_d.conf.LABELS)\n","            d_pred_df = pd.concat([messages_df[['nick']], d_pred_df], axis=1)\\\n","                .groupby('nick')\\\n","                .first()\n","            decisionsD = d_pred_df[task_d.conf.LABELS].round(5).to_dict(orient='index')\n","            print(\"Decisions D:\")\n","            pprint(decisionsD)\n","\n","            print(\"Decisions C:\")\n","            decisionsC = d_pred_df[task_d.conf.LABELS]\\\n","                .apply(np.argmax, axis=1)\\\n","                .replace(dict(enumerate(d_pred_df.columns)))\\\n","                .to_dict()\n","            pprint(decisionsC)\n","           \n","            print(\"Emmisions of C and D:\")\n","            self.tracker.stop()\n","            df = pd.read_csv(\"emissions.csv\")\n","            measurementsCD = df.iloc[-1][self.relevant_cols].to_dict()\n","            pprint(measurementsCD)\n","\n","            self.submit_decission(0, decisionsA, measurementsAB, retries, backoff) # task2a\n","            self.submit_decission(1, decisionsB, measurementsAB, retries, backoff) # task2b\n","            self.submit_decission(2, decisionsC, measurementsCD, retries, backoff) # task2c\n","            self.submit_decission(3, decisionsD, measurementsCD, retries, backoff) # task2d\n","\n","            # Only one GET request for each round\n","            messages = self.get_messages(retries, backoff)\n","            # messages = []\n","\n","        print(\"All rounds processed\")"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7394,"status":"ok","timestamp":1684837153421,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"kTWjXRZHHmGE","outputId":"72354ede-c216-49cd-a307-e7c5145301ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["[codecarbon INFO @ 10:19:09] [setup] RAM Tracking...\n","[codecarbon INFO @ 10:19:09] [setup] GPU Tracking...\n","[codecarbon INFO @ 10:19:09] Tracking Nvidia GPU via pynvml\n","[codecarbon INFO @ 10:19:09] [setup] CPU Tracking...\n","[codecarbon WARNING @ 10:19:09] No CPU tracking mode found. Falling back on CPU constant mode.\n","[codecarbon WARNING @ 10:19:12] We saw that you have a Intel(R) Xeon(R) CPU @ 2.30GHz but we don't know it. Please contact us.\n","[codecarbon INFO @ 10:19:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.30GHz\n","[codecarbon INFO @ 10:19:12] >>> Tracker's metadata:\n","[codecarbon INFO @ 10:19:12]   Platform system: Linux-5.15.107+-x86_64-with-glibc2.31\n","[codecarbon INFO @ 10:19:12]   Python version: 3.10.11\n","[codecarbon INFO @ 10:19:12]   CodeCarbon version: 2.2.1\n","[codecarbon INFO @ 10:19:12]   Available RAM : 12.678 GB\n","[codecarbon INFO @ 10:19:12]   CPU count: 2\n","[codecarbon INFO @ 10:19:12]   CPU model: Intel(R) Xeon(R) CPU @ 2.30GHz\n","[codecarbon INFO @ 10:19:12]   GPU count: 1\n","[codecarbon INFO @ 10:19:12]   GPU model: 1 x Tesla T4\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"modeloB\")\n","model_b = Trainer(\n","  model=model,\n","  args=TrainingArguments(\"./loaded_outputs_b\"),\n","  eval_dataset=messages\n",")"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1684837341260,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"kTz_WtsZFmVQ","outputId":"ab197042-2780-414f-8054-e9de1c06160d"},"outputs":[{"data":{"text/plain":["{'timestamp': '2023-05-23T10:19:46',\n"," 'project_name': 'codecarbon',\n"," 'run_id': '485169cb-887a-44fc-80cc-23f78534aca1',\n"," 'duration': 22.07438945770264,\n"," 'emissions': 6.627390819588935e-06,\n"," 'emissions_rate': 3.002298583291677e-07,\n"," 'cpu_power': 42.5,\n"," 'gpu_power': 72.23,\n"," 'ram_power': 1.9307284355163572,\n"," 'cpu_energy': 8.580601049794092e-06,\n"," 'gpu_energy': 1.4256761204534108e-05,\n"," 'ram_energy': 3.756116278293575e-07,\n"," 'energy_consumed': 2.321297388215756e-05,\n"," 'country_name': 'United States',\n"," 'country_iso_code': 'USA',\n"," 'region': 'south carolina',\n"," 'cloud_provider': nan,\n"," 'cloud_region': nan,\n"," 'os': 'Linux-5.15.107+-x86_64-with-glibc2.31',\n"," 'python_version': '3.10.11',\n"," 'codecarbon_version': '2.2.1',\n"," 'cpu_count': 2,\n"," 'cpu_model': 'Intel(R) Xeon(R) CPU @ 2.30GHz',\n"," 'gpu_count': 1.0,\n"," 'gpu_model': '1 x Tesla T4',\n"," 'longitude': -79.9746,\n"," 'latitude': 32.8608,\n"," 'ram_total_size': 12.67839813232422,\n"," 'tracking_mode': 'process',\n"," 'on_cloud': 'N'}"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv(\"emissions.csv\").iloc[-1].to_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SdkaJgu3rEC"},"outputs":[],"source":["from pprint import pprint\n","decisionsB =  b_pred_df['pred_b'].apply(lambda x: np.round(x, 5)).to_dict()\n","decisionsA = b_pred_df['pred_b'].round().astype(int).to_dict()\n","\n","decisionsD = d_pred_df[task_d.conf.LABELS].round(5).to_dict(orient='index')\n","\n","decisionsC = d_pred_df[task_d.conf.LABELS]\\\n","                .apply(np.argmax, axis=1)\\\n","                .replace(dict(enumerate(d_pred_df.columns)))\\\n","                .to_dict()\n","print(\"Decisions A\")\n","pprint(decisionsA)\n","print(\"Decisions B\")\n","pprint(decisionsB)\n","print(\"Decisions C\")\n","pprint(decisionsC)\n","print(\"Decisions D\")\n","pprint(decisionsD)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gMXuHLciXIO3"},"source":["# Main"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KvhdFtEajwmp"},"source":["Please, replace the symbol 'X' by the desired task. For example, for task 1 it would be: task1, task1a and task1b."]},{"cell_type":"code","execution_count":114,"metadata":{"executionInfo":{"elapsed":505,"status":"ok","timestamp":1684837095582,"user":{"displayName":"SIMON SANCHEZ VILORIA","userId":"07996891288581950477"},"user_tz":-120},"id":"GZrDpxNAS6-3"},"outputs":[],"source":["def download_data():\n","    download_messages_trial(\"task2\", [\"task2a\", \"task2b\", \"task2c\", \"task2d\"], TOKEN)\n","\n","def get_post_data():\n","    # Emissions Tracker Config\n","    config = {\n","        \"save_to_file\": True,\n","        \"log_level\": \"DEBUG\",\n","        \"tracking_mode\": \"process\",\n","        \"output_dir\": \".\", \n","    }\n","    tracker = EmissionsTracker(**config)\n","\n","    number_runs = 3 # Max: 3\n","\n","    # Prediction period\n","    client_task2 = Client_task2(\"task2\", [\"task2a\", \"task2b\", \"task2c\", \"task2d\"], TOKEN, number_runs, tracker)\n","    client_task2.run_task2(5, 0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    # download_data()\n","    get_post_data()"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"113HHJf-Ixtpn8j6mSyRe0IYWsLBf9xDw","timestamp":1684164676863}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
